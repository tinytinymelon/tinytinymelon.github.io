{"meta":{"title":"梅子黄时雨","subtitle":"","description":"","author":"Leo Zhou","url":"http://yoursite.com","root":"/"},"pages":[],"posts":[{"title":"Compile LLVM & Clang @ Windows","slug":"Compile-LLVM-Clang-Windows","date":"2019-12-16T14:18:07.000Z","updated":"2019-12-16T15:06:36.202Z","comments":true,"path":"2019/12/16/Compile-LLVM-Clang-Windows/","link":"","permalink":"http://yoursite.com/2019/12/16/Compile-LLVM-Clang-Windows/","excerpt":"","text":"1. Prepare EnvironmentWe need : cmake: https://cmake.org/download/, choose windows version git: https://git-scm.com/download/win Visual Studio 2019: https://visualstudio.microsoft.com/, Community Version is enough 2. Clone LLVM projectTwo ways to get LLVM project source code git clone —config core.autocrlf=false https://github.com/llvm/llvm-project.git download source code from : http://releases.llvm.org/download.html However, the second way needs you put clang source code into llvm/tools with folder name as clang the build script will check if the folder existed and build clang project at same time if so The first way needs to add -DLLVM_ENABLE_PROJECTS flags to enable related project, the project could be clang, clang-tools-extra, libcxx, libcxxabi, libunwind, lldb, compiler-rt, lld, polly, or debuginfo-test. 3. Use CMake to generated .sln fileuse first one as example: 12345cd llvm-projectmkdir buildcd buildcmake -G &lt;generator&gt; [options] ../llvm Based on Visual Studio version you installed, the generator could be: description Visual Studio 16 2019 Generates Visual Studio 2019 project files. Use -A option to specify architecture. Visual Studio 15 2017 [arch] Generates Visual Studio 2017 project files. Optional [arch] can be “Win64” or “ARM”. Visual Studio 14 2015 [arch] Generates Visual Studio 2015 project files. Optional [arch] can be “Win64” or “ARM”. Visual Studio 12 2013 [arch] Generates Visual Studio 2013 project files. Optional [arch] can be “Win64” or “ARM”. Visual Studio 11 2012 [arch] Generates Visual Studio 2012 project files. Optional [arch] can be “Win64” or “ARM”. Visual Studio 10 2010 [arch] Generates Visual Studio 2010 project files. Optional [arch] can be “Win64” or “IA64”. Visual Studio 9 2008 [arch] Generates Visual Studio 2008 project files. Optional [arch] can be “Win64” or “IA64”. It will take some time to generate related LLVM.sln file in folder builder. 4. Open Project and CompileNow you could open the LLVM.sln, Visual Studio will automatically load all related resources to build up the LLVM project. Normally, it will take a long time (&gt;1.5h) to build up whole project in Vistual Studio. After it done its work, you could get the clang/llc binary in one debug output folder. It’s a good choice to have a meal after you start the building process and check it when you’ve enjoied the dinner. :) Have a wonderful time in LLVM world.","categories":[],"tags":[{"name":"LLVM","slug":"LLVM","permalink":"http://yoursite.com/tags/LLVM/"}]},{"title":"Compile LLVM & Clang @ Ubuntu 18.04","slug":"Compile-LLVM-Clang-Ubuntu-18-04","date":"2019-12-11T13:34:54.000Z","updated":"2019-12-11T14:07:53.819Z","comments":true,"path":"2019/12/11/Compile-LLVM-Clang-Ubuntu-18-04/","link":"","permalink":"http://yoursite.com/2019/12/11/Compile-LLVM-Clang-Ubuntu-18-04/","excerpt":"","text":"1. Prepare EnvironmentUse apt to install required pakcage: 1234sudo apt updatesudo apt upgradesudo apt install build-essential cmake python3-dev libncurses5-d make 2. Download the source codeYou may clone it from github, containting latest code and being able to upstream: 1git clone https://github.com/llvm/llvm-project.git However, it will contain all history and dev code, leading to long time when downloading the source code. If network status is poor, better to download each latest source code for llvm and clang in LLVM Download Page. Take LLVM 9.0 as example: LLVM Source Code Clang source code You will get two tar.gz: llvm-9.0.0.src.tar.xz cfe-9.0.0.src.tar.xz Clang source code should put into folder ${LLVM_SOURCE_CODE}/tools/clang(checking INSTALL.txt in clang source file). the final path as: 12345llvm-9.0.0-src ... |- tools ... |- clang (renamed from cfe-9.0.0) 3. Build Code1234mkdir buildcd buildcmake -G &quot;Unix Makefiles&quot; ../llvm-9.0.0-src It will scan CMakefiles.txt, automatically involving clang project. 4. Check Resultbin folder will be found in build folder. Setup the Path in ~/.bashrc : 1export PATH=$&#123;BUILD_FOLDER&#125;/bin:$&#123;PATH&#125; Then source ~/.bahsrc. Now checking with command clang and llc.","categories":[],"tags":[{"name":"LLVM","slug":"LLVM","permalink":"http://yoursite.com/tags/LLVM/"},{"name":"Build","slug":"Build","permalink":"http://yoursite.com/tags/Build/"}]},{"title":"野猪书第四，五，六章读书笔记","slug":"wild-pig-chapter-4-5-6","date":"2019-12-07T15:03:30.000Z","updated":"2019-12-07T15:05:04.728Z","comments":true,"path":"2019/12/07/wild-pig-chapter-4-5-6/","link":"","permalink":"http://yoursite.com/2019/12/07/wild-pig-chapter-4-5-6/","excerpt":"","text":"第四章：Overview数据结构需要改动时候，一般需要更新代码或者内部数据结构，此时会碰到两个问题： 滚动更新数据库相对复杂 依赖客户更新不可靠 这种情况下，新旧数据会同时存在系统中，需要双向兼容： 向后兼容：新代码可以读取旧数据 向前兼容：旧代码可以读取新数据 语言内置编码方案问题 和语言绑定的编码方案往往是语言specified 对象的序列化和反序列化往往需要跳过一些安全check，注入恶意代码变得有可能。比如在java默认构造函数中注入代码。 不同版本之间的实现往往是不兼容的，最明显的就是Java的jackson系列json序列化lib 性能也往往不是这些lib着重考虑的因素 数据流转方式 通过数据库 通过service call: Rest and RPC 通过异步message发送 缓冲区更好的可靠性 自动重发 message queue隐藏发送方信息 多个接收方 解耦发送和接收方，通过message queue 第五章：Overviewreplication考虑因素 single leader, multi leader and leaderless 单主节点：只有一个节点负责写入 多主节点：多节点写入 无主节点：所有节点都可以写入 数据一致性方式：synchronous或者asynchronous 可以一个节点同步，保证已经额外有一份copy，然后其他的进行异步同步，也可以叫半同步 handle failed replica read-your-writes and mono‐ tonic reads guarantees. CS模式配置新节点 一般使用snapshot的方式来配置新的节点 然后通过数据更新日志来更新新节点 处理节点失效 追赶式恢复 -&gt; 通过磁盘的日志 基于语句的复制 -&gt; 比如记录输入的SQL语句 now()，random()等函数是非确定的 自递增的column不适适用 where等语句效果取决于数据情况 带副作用的操作，比如触发器，用户定义函数 基于预写日志(WAL)传输 日志即存储，日志结构的存储引擎（SSTables和LSM-trees） 覆盖型的写入(B-tree)，日志作为内存中，尚未刷入磁盘的备份 基于行的逻辑日志复制 一系列记录数据行级，但是更加详细和准确的描述，比如mysql的binlog 基于触发器的复制 -&gt; 类似event 复制滞后的问题 读自己的写 -&gt; 也就是所谓的写后读，写完以后进行读取，此时可能读取到一个尚未得到更新数据的节点 目标就是：读写一致性 记录节点更新时间 引入最后请求时间戳 单调读 -&gt; 两次从不同的两个节点可能读到不同的数据 始终保持在一个节点上读，除非节点失效，保证不会一次读取新的以后再另外一个节点读到旧的数据。 单调读一致性 前缀一致读：一系列的数据读取得到的数据顺序和写入顺序保持一致 不相关的数据读取顺序不需要和写入顺序一致 解决方法之一：相关数据由同一节点处理 多主节点避免冲突 类似于hash，相同或者类同数据只在一个节点处理 给每一个写都带一个UUID 自定义冲突解决逻辑： 在写入时候解决，写入时候发现冲突要求解决 在读取时候解决，返回多个可能结果，让用户自己选择 自动冲突解决： 无冲突的复制数据类型 可合并的持久数据结果 操作转换 无主节点复制还是多看论文把。 第六章：数据分区分区定义：每一条数据只属于某个特定的分区。 如何分区 随机分发分区 -&gt; 代价是每次查询都需要扫描全局 基于关键字分区 首先对关键字进行排序，分段进行分区 内部可以使用SSTables和LSM-Trees保存 不合适的关键字选择容易出现热点节点 基于hash分区 不支持range搜索 -&gt; 容易退化成全局搜索 折衷 -&gt; 复合主键 一个键做hash，其他作为排序 所以核心就是选择合适的key作为hash 一致性哈希 分区和二级索引二级索引索引就是非主键索引以外的索引，而主键索引一般是作为分区来作用的。 很多数据库不支持二级索引，比如HBase。 有两种主要的方法来支持二级索引的分区 基于文档的分区 各个分区独自保存自己的二级索引 实现简单，写快，但是读时候性能难讲 更加类似于分区local的二级索引 基于词条的分区 基于全局进行索引build 同时对这个索引构建主键进行分区操作 写时候性能变差，但是读的时候优势 更新异步的话，可以减少写性能损失 分区调整： 固定数据数量 动态分区 按节点比例分区 请求路由三种方式client到数据节点： 随机选择一个节点，如果不对，那么节点进行转发 中间有一层路由层，了解所有分区信息，然后进行转发 客户端自己有所有分区信息，直接读取节点 并行查询执行多个或者复杂的查询可以拆分成更加fragement的操作，分到不同的节点，提高性能。","categories":[],"tags":[{"name":"Storage","slug":"Storage","permalink":"http://yoursite.com/tags/Storage/"},{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"系统设计，分布式","slug":"系统设计，分布式","permalink":"http://yoursite.com/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%EF%BC%8C%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"Linux Interrupt Part 1","slug":"Linux-Interrupt-Part-1","date":"2019-12-05T14:49:18.000Z","updated":"2019-12-16T15:09:22.958Z","comments":true,"path":"2019/12/05/Linux-Interrupt-Part-1/","link":"","permalink":"http://yoursite.com/2019/12/05/Linux-Interrupt-Part-1/","excerpt":"","text":"1. 中断设计constrains 中断应该是尽量能够快速响应的，否则类似网络传输的数据可能丢失 因此linux将中断处理设计成了urgent的部分+可以defer处理的部分 中断处理必须考虑重入问题，在处理一个中断时候处理其他中断 中断可以被屏蔽的，disabled 2. 中断和异常中断(interrupt) 可屏蔽中断(Maskable interrupts) 所有Device触发的Interrupt Requests(IRQs)都是可屏蔽中断 不可屏蔽中断(Nonmaskable interrupts) 一些重要的events(比如硬件故障)是不可屏蔽中断 异常(exception) Processor-detected exceptions: Generated when the CPU detects an anomalous condition when execution instruction. 进一步的细分成三种： Faults: 可恢复，返回当前运行的指令。跳转到前的指令存在EIP中 Traps: 回到下一条指令继续运行 Aborts: process只能被terminated，不过可以在这里检索错误现场 可编程的异常(Programmed exceptions): Occur at the request of the programmer. 比如INT指令或者INT 3 into或者bound指令失败时候也会触发 一般被叫做software interrupts 一般用作系统调用或者debug 所有中断和异常使用unsigned 8bits来作为index，这个值被intel称为vector。 3. IRQs and Interrupts所有的device controller都可以被指定一条或者多条Interrupt ReQest(IRQ) line. 所有existing IRQ lines都被绑定到专用硬件的input pins上。这个硬件叫Programmable Interrupt Controller(可编程中断控制器)。 PIC的具体流程如下： 检测所有连接的IRQ lines是否有raised signals。如果有多个IRQ lines被raised，那么选择lower pin的number。 如果有IRQ line被raise convert raised signal to对应的vector 将vector保存在一个Interrupt Controller I/O port，这使得cpu可以通过data bus读到这个vector send一个raised signal到CPU的INTR pin，触发一个中断 等待cpu acknowldege the interrupt signal by writting into one of the Programmable Interrupt Controllers(PIC) I/O ports. 在此之后，clear INTR line. 回到step 1 IRQ定义从0开始，也就是IRQ0，对应的intel的vector值从32开始。但是具体的对应的关系，是可以通过编程来定义的。 IRQ的line是可以选择性的ignored，但是对应的signal不会被丢失，会在un-ingore时候触发该有的操作。 注意，这里的ignore和可屏蔽的中断的屏蔽是两个概念。EFLAGS中的IF flag的屏蔽和恢复(cli and sti)都是针对于所有IRQ lines。 最早的PIC设备是2片8259A芯片，支持15个IRQs(主片的IRQ2 pin接到了从片上)。同时8259A芯片不支持多核（SMP）。 4. APIC (Advanced Programmable Interrupt Controller)为了支持SMP，引入了APIC，包括： local APIC，包含LINT0和LINT1两个pin接口，在模拟8259A芯片时候，可以一个作为INTR，一个作为NMI。 I/O APIC，作为对接设备的LB存在，负责接收device， controller的singal，然后负责分发。也能模拟8259A芯片。 可编程，提供复杂的IRQ和vector的映射关系 同时通过各自的Interrupt Command Register(ICR)，各个core之间也可以相互发送消息（中断），称为interprocessor interrupt (IPIs) I/O APIC的分发可以是static的（类似affinity），也可以使用round robin的方式。 5. Required Exceptionsvector最小的一系列exception(0-19)是intel定义，并且每个os都必须又对应的handler进行处理的。linux对于这些exception，每个注册了对应的exeption handler，这些handler大部分最终会send相对应的SIGNAL来方便其他程序监听和处理。比较有意思的几个如下： Exception Exception handler Signal 14 Page Fault page_fault( ) SIGSEGV 17 Alignment check alignment_check( ) SIGBUS 6. IDTIDT中可以保存三类gate： Task Gate：保存了一个TSS的段选择器，简单来说就是当这个exception handler被触发时候，会发生task的切换来进行处理 Interrupt Gate：保存普通的段选择器+offset，用来指向对应的处理代码入口；Interrupt Gate触发时候会clear IF flag来屏蔽中断。 Trap Gate：和Interrupt Gate一样，保存普通的段选择器+offset，但是不会屏蔽中断 总体来说，Linux uses interrupt gates to handle interrupts and trap gates to handle exceptions. 7. Interrupt Trigger ProcessTrigger process 从GDTR获取GDT的信息，然后取得对应的段描述符 比较权限，需要满足下述条件，否则throw “General Protection”: 对于非用户触发的Interrupt，CPL &lt;= DPL，也就是说interrupt handler权限要不小于触发中断的程序的权限，否则无法进行处理中断。 对于用户触发的Interrupt，需要CPL =&gt; DPL，也就是说用户的权限要不小于触发的handler的权限，否则用户可以去调用其他的interrupt或者trap gate。 如果CPL和DPL的权限不同，那就需要切换到DPL对应级别的TSS和Stack上 首先读取当前的ss和esp信息（当前stack信息） 从需要切换到对象的TSS中读取对应的ss和esp信息 将当前的ss和esp信息保存在切换后的stack中 如果是fault，那么需要同时需要保存cs和eip，等待handler后返回现场（逻辑地址）；最后保存eflags。如果有hardware error code，同样保存在stack上。 从段描述符中读取基地址，加上offset，得到目标逻辑地址并设置cs和eip，开始执行interrupt handler。 在interrupt handler完成工作后，需要返回到原有的进程中，一般通过iret命令，其包括如下的操作： 从当前stack上获取cs，eip和eflags。 如果权限之前发生过切换，那么需要恢复到原有的stack上，ss和esp同样保存在interrupt handler的stack上 恢复stack，恢复cs，eip和eflags 检查ds，es，fs和gs的DPL是否小于恢复后的CPL，如果是，那么进行清空。这是以防用户进程获取的系统权限级别的段描述符。 8. Interrupt GateGate类型： Interrupt gate DPL = 0 处理内部的中断(interrupt) System gate DPL = 3 vector 4(into), 5(bound)和128(int 0x80)使用这个gate System interrupt gate DPL = 3 int3, User Mode的Debug Trap gate DPL = 0 大部分内部异常(exception)依赖于这个 Task gate DPL = 0 handle double fault 9. IDT初始化5.4 kernel中和UTLK中的实现已经有所不同了 9.1. legacy mode在4.x版本中，初始化依然是通过”函数”： 1234567891011121314151617181920oid __init trap_init(void)&#123; int i; set_intr_gate(X86_TRAP_DE, divide_error); set_intr_gate_ist(X86_TRAP_NMI, &amp;nmi, NMI_STACK); /* int4 can be called from all */ set_system_intr_gate(X86_TRAP_OF, &amp;overflow); set_intr_gate(X86_TRAP_BR, bounds); set_intr_gate(X86_TRAP_UD, invalid_op); set_intr_gate(X86_TRAP_NM, device_not_available);#ifdef CONFIG_X86_32 set_task_gate(X86_TRAP_DF, GDT_ENTRY_DOUBLEFAULT_TSS);#else set_intr_gate_ist(X86_TRAP_DF, &amp;double_fault, DOUBLEFAULT_STACK);#endif...&#125; set_intr_gate负责设置interrupt gate： 12345678910111213141516set_intr_gate(n, addr) |- set_intr_gate_notrace(n, addr); |- _set_gate(n, GATE_INTERRUPT, (void *)addr, 0, 0, __KERNEL_CS); |- pack_gate(&amp;s, type, (unsigned long)addr, dpl, ist, seg); |- write_idt_entry(idt_table, gate, &amp;s); |- write_trace_idt_entry(gate, &amp;s); // trace |- _trace_set_gate // linux trace // write#define write_idt_entry(dt, entry, g) native_write_idt_entry(dt, entry, g)static inline void native_write_idt_entry(gate_desc *idt, int entry, const gate_desc *gate)&#123; memcpy(&amp;idt[entry], gate, sizeof(*gate));&#125; 可以看到set_intr_gate等一些列操作，最终是往内存的一个位置(idt_table)写入对应的gate信息。 idt_table在head_32.S中被定义： 123idt_descr: .word IDT_ENTRIES*8-1 # idt contains 256 entries .long idt_table 对于64bit的定义在arch/x86/kernel/cpu/common.c中： 12345#ifdef CONFIG_X86_64struct desc_ptr idt_descr __ro_after_init = &#123; .size = NR_VECTORS * 16 - 1, .address = (unsigned long) idt_table,&#125;; 随后会被lidt命令把地址写入idtr中： 12345678910111213141516/* * The load_current_idt() must be called with interrupts disabled * to avoid races. That way the IDT will always be set back to the expected * descriptor. It&apos;s also called when a CPU is being initialized, and * that doesn&apos;t need to disable interrupts, as nothing should be * bothering the CPU then. */static inline void load_current_idt(void)&#123; if (is_debug_idt_enabled()) load_debug_idt(); else if (is_trace_idt_enabled()) load_trace_idt(); else load_idt((const struct desc_ptr *)&amp;idt_descr);&#125; 而lidt的会读取desc_ptr struct的size作为limit，address作为idt的base： 123456789101112131415IF OperandSize = 16 THEN IDTR(Limit) ← SRC[0:15]; IDTR(Base) ← SRC[16:47] AND 00FFFFFFH; ELSE IF 32-bit Operand Size THEN IDTR(Limit) ← SRC[0:15]; IDTR(Base) ← SRC[16:47]; FI; ELSE IF 64-bit Operand Size (* In 64-Bit Mode *) THEN IDTR(Limit) ← SRC[0:15]; IDTR(Base) ← SRC[16:79]; FI;FI; 9.2. kernel version 5.45.4 kernel中初始化有改变，set_intr_gate没有了，或者说设置default idt的值不通过set_intr_gate。不过idt_table之类的还是在的，依旧做为idt的内存存储： 1234567891011121314151617181920212223242526/* * The default IDT entries which are set up in trap_init() before * cpu_init() is invoked. Interrupt stacks cannot be used at that point and * the traps which use them are reinitialized with IST after cpu_init() has * set up TSS. */static const __initconst struct idt_data def_idts[] = &#123; INTG(X86_TRAP_DE, divide_error), INTG(X86_TRAP_NMI, nmi), ...#ifdef CONFIG_X86_32 TSKG(X86_TRAP_DF, GDT_ENTRY_DOUBLEFAULT_TSS),#else INTG(X86_TRAP_DF, double_fault),#endif INTG(X86_TRAP_DB, debug), SYSG(X86_TRAP_OF, overflow),#if defined(CONFIG_IA32_EMULATION) SYSG(IA32_SYSCALL_VECTOR, entry_INT80_compat),#elif defined(CONFIG_X86_32) SYSG(IA32_SYSCALL_VECTOR, entry_INT80_32),#endif&#125;; 可以看到，set_intr_gate变成了INTG的宏： 1234567891011121314#define G(_vector, _addr, _ist, _type, _dpl, _segment) \\ &#123; \\ .vector = _vector, \\ .bits.ist = _ist, \\ .bits.type = _type, \\ .bits.dpl = _dpl, \\ .bits.p = 1, \\ .addr = _addr, \\ .segment = _segment, \\ &#125;/* Interrupt gate */#define INTG(_vector, _addr) \\ G(_vector, _addr, DEFAULT_STACK, GATE_INTERRUPT, DPL0, __KERNEL_CS) 这里的idt_data定义如下： 123456struct idt_data &#123; unsigned int vector; unsigned int segment; struct idt_bits bits; const void *addr;&#125;; 而def_idts的值会在函数idt_setup_from_table中写入： 123456789101112static voididt_setup_from_table(gate_desc *idt, const struct idt_data *t, int size, bool sys)&#123; gate_desc desc; for (; size &gt; 0; t++, size--) &#123; idt_init_desc(&amp;desc, t); write_idt_entry(idt, t-&gt;vector, &amp;desc); if (sys) set_bit(t-&gt;vector, system_vectors); &#125;&#125; 该这么多是为了保证代码整洁，原来的32和64bit定义分开，这里统一到了一起。 9.3. ignore irq handler在irq handler初始化之前，所有的对应的idt entry都会被设置成 head_32.S中的early_ignore_irq(老版本是ignore_int)，代码基本一致： 1234567891011121314151617181920212223242526272829303132/* This is the default interrupt &quot;handler&quot; :-) */ENTRY(early_ignore_irq) cld#ifdef CONFIG_PRINTK pushl %eax pushl %ecx pushl %edx pushl %es pushl %ds movl $(__KERNEL_DS),%eax movl %eax,%ds movl %eax,%es cmpl $2,early_recursion_flag je hlt_loop incl early_recursion_flag pushl 16(%esp) pushl 24(%esp) pushl 32(%esp) pushl 40(%esp) pushl $int_msg call printk call dump_stack addl $(5*4),%esp popl %ds popl %es popl %edx popl %ecx popl %eax#endif iret 9.4 Typical Exception Handler Process基本的exception处理流程包括如下几步： 保存error code，jmp到通用的exception handler流程 legacy mode: error_code latest(5.4): common_exception 通用的exception handler流程会首先保存context 调用对应的c代码的handler(地址保存在%edi中) 调用ret_from_exception开始返回 调用restore_all_kernel 检查是否有中断 恢复stack frame随后iret 更加完整的流程描述如下： Saves the registers that might be used by the high-level C function on the stack. Issues a cld instruction to clear the direction flag DF of eflags, thus making surethat autoincreases on the edi and esi registers will be used with stringinstructions.* Copies the hardware error code saved in the stack at location esp+36 in edx.Stores the value –1 in the same stack location. As we’ll see in the section “Reexecution of System Calls” in Chapter 11, this value is used to separate 0x80 exceptions from other exceptions. Loads edi with the address of the high-level do_handler_name( ) C functionsaved in the stack at location esp+32; writes the contents of es in that stacklocation. Loads in the eax register the current top location of the Kernel Mode stack. Thisaddress identifies the memory cell containing the last register value saved instep 1. Loads the user data Segment Selector into the ds and es registers. Invokes the high-level C function whose address is now stored in edi. 以下，举处除零的handler为例。 9.4.1. Legacy do_divide_error实现12345678ENTRY(divide_error) RING0_INT_FRAME ASM_CLAC pushl_cfi $0 # no error code pushl_cfi $do_divide_error jmp error_code CFI_ENDPROCEND(divide_error) error_code是共享的处理流程，其中会调用到do_divide_error函数： 1234567891011error_code: ... # push registers cld ... # build up do_divide_error function stack call *%edi # call do_divide_error function jmp ret_from_exception CFI_ENDPROCEND(page_fault) do_divide_error是个c程序，定义在traps.c中的宏DO_ERROR_INFO，最终会调用do_trap来： 1234567891011121314151617181920212223#define DO_ERROR_INFO(trapnr, signr, str, name, sicode, siaddr) \\dotraplinkage void do_##name(struct pt_regs *regs, long error_code) \\&#123; \\ ... conditional_sti(regs); \\ do_trap(trapnr, signr, str, regs, error_code, &amp;info); \\ exception_exit(prev_state); \\&#125;// do_trapstatic void __kprobesdo_trap(int trapnr, int signr, char *str, struct pt_regs *regs, long error_code, siginfo_t *info)&#123; struct task_struct *tsk = current; ... if (info) force_sig_info(signr, info, tsk); else force_sig(signr, tsk);&#125; 最后一步是想当前程序发送一个SIGFPE signal。ret_from_exception和5.4版本中功能类似，后面一起讲。 9.4.2. Linux 5.4 kernel实现：9.4.2.1. 32bit divide_error代码在entry_32.S中 123456ENTRY(divide_error) ASM_CLAC pushl $0 # 这里保存error code，0代表没有 pushl $do_divide_error # 这里保存目标c程序地址 jmp common_exceptionEND(divide_error) common_exception是通用的exception处理流程（除了double fault）： 123456789101112131415161718192021common_exception: /* the function address is in %gs&apos;s slot on the stack */ SAVE_ALL switch_stacks=1 skip_gs=1 ENCODE_FRAME_POINTER UNWIND_ESPFIX_STACK /* fixup %gs */ GS_TO_REG %ecx movl PT_GS(%esp), %edi # get the function address REG_TO_PTGS %ecx SET_KERNEL_GS %ecx /* fixup orig %eax */ movl PT_ORIG_EAX(%esp), %edx # get the error code movl $-1, PT_ORIG_EAX(%esp) # no syscall to restart TRACE_IRQS_OFF movl %esp, %eax # pt_regs pointer CALL_NOSPEC %edi # 跳转到对应的c历程 jmp ret_from_exceptionEND(common_exception) 除去一堆保存环境和测试的，这里要关注的就是跳转到c handler的代码。 9.4.2.2. 64bit divide_error实现代码在entry_64.S中： 123idtentry divide_error do_divide_error has_error_code=0// idtentry - Generate an IDT entry stub idtentry: generates an IDT stub that sets up a usable kernel context, creates struct pt_regs, and calls @do_sym. 9.4.2.2 c handlerdo_divide_error实现在arch\\x86\\kernel\\traps.c 123456789101112131415161718192021222324252627#define IP ((void __user *)uprobe_get_trap_addr(regs))#define DO_ERROR(trapnr, signr, sicode, addr, str, name) \\dotraplinkage void do_##name(struct pt_regs *regs, long error_code) \\&#123; \\ do_error_trap(regs, error_code, str, trapnr, signr, sicode, addr); \\&#125;DO_ERROR(X86_TRAP_DE, SIGFPE, FPE_INTDIV, IP, \"divide error\", divide_error)static void do_error_trap(struct pt_regs *regs, long error_code, char *str, unsigned long trapnr, int signr, int sicode, void __user *addr)&#123; RCU_LOCKDEP_WARN(!rcu_is_watching(), \"entry code didn't wake RCU\"); /* * WARN*()s end up here; fix them up before we call the * notifier chain. */ if (!user_mode(regs) &amp;&amp; fixup_bug(regs, trapnr)) return; if (notify_die(DIE_TRAP, str, regs, error_code, trapnr, signr) != NOTIFY_STOP) &#123; cond_local_irq_enable(regs); do_trap(trapnr, signr, str, regs, error_code, sicode, addr); &#125;&#125; 类似的，这里也会调用的通用do_trap实现中去。 9.5. 返回完成调用以后，ret_from_exception负责返回到原来进程中。 123456ret_from_exception - restore_all_kernel - .Lno_preempt - .Lirq_return - IRET_FRAME -&gt; 回复堆栈 - INTERRUPT_RETURN -&gt; iret 或者 jmp native_iret 10. 中断(Interrupt) 异常最终的操作基本都是发signal给当前的进程，这是因为异常的发生往往是in time的。 但是对于中断，中断的trigger往往是异步的，触发时候目标进程可能在sleep状态，也就是说当前进程不是中断的目标进程。 中断细节可以分成如下几类： I/O interrupts Timer interrupts local APIC timer or an external timer Interprocessor interrupts 10.1. I/O interrupts多台设备可能绑在同一个I/O interrupt上，使用同一条IRQ line。此时，需要一种分享的方式，一般有两种方式： IRQ sharing: 多个设备使用同一个interrupt service routines (ISRs)，这个routine需要去判断到底哪一个设备发送了中断。 IRQ dynamic allocation: 一次只让一个设备使用，只有激活状态的设备可以尝试独占IRQ line。 另一方面，对于中断处理程序，因为其会屏蔽中断，并且可能被switch出去，所以linux会把中断处理后可能的操作分成三类： Critical Noncritical Noncritical deferrable","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"Micro","slug":"Micro","permalink":"http://yoursite.com/tags/Micro/"},{"name":"Interrupt","slug":"Interrupt","permalink":"http://yoursite.com/tags/Interrupt/"}]},{"title":"野猪书第三章读书笔记","slug":"wild-pig-chapter3","date":"2019-11-21T06:10:59.000Z","updated":"2019-12-05T15:04:13.542Z","comments":true,"path":"2019/11/21/wild-pig-chapter3/","link":"","permalink":"http://yoursite.com/2019/11/21/wild-pig-chapter3/","excerpt":"","text":"1. overview数据库分类 事务处理型 数据分析型 存储索引家族： 日志结构的存储引擎 面向页的存储引擎，比如b-tree 2. 哈希表索引核心：将key hash到对应的文件位置 使用日志方式，不修改已有记录，在末尾增加 如果能够保持key在内存中，那么写入速度会很快 将日志分段，到一定大小，生成新的段 在合适时机进行段合并，只保留最新的结果 使用后台线程，在完成合并之前使用老的index 合并之后切换到新的index，删除老的index 最终，每一个段都会有自己的索引（注意，可能有多个段） 搜索需要从最新的段开始往前找索引表 在实现中还需要考虑： 文件格式：二进制 &gt; CSV 删除记录：可以通过标记，在合并时候处理被删除的key 崩溃回复：如果重启引起内存中的key map丢失，可以 从头开始扫描文件，重建key map 或者在平时就定时将key map映射到磁盘之上 部分写入的记录：写日志中也有可能崩溃，加入校验值来发现损坏情况。 并发控制：因为段是需要严格顺序写入的，因此 写必须是单线程 读可以多线程 为什么之追加不直接修改文件： 顺序写性能会好很多，特别对于HDD。但是对于SSD或者nvme磁盘如何呢？ 因为追加是只读的，因此兵法和崩溃恢复都简单很多。 合并旧段可以减轻文件碎片化问题 哈希表索引局限性： 索引哈希表必须全部放入内存，如果spill到磁盘上，性能会收到影响；另外，哈希变满时候，哈希冲突会影响性能。 区间查询效率不高：就是说相邻的key的value值分布基本不会是相邻的，因此扫描一个range的keys，需要逐个查找其中的每一个key。 换句话说，你没办法知道range中哪些key是存在的，只能一个一个测试。 3. SSTable索引哈希表索引中保存在文件中的key-value值对是不排序的，出现的顺序基本是按照写入的顺序的来的，无论是原始文件还是合并后的文件。 如果我们要求磁盘上的文件值对，都是按照key的顺序来保存。那么会有如下好处： 合并两个segment file会变得高效 内存中的索引不需要保存所有key的索引信息，只需要保存几个作为标点的key的索引，其他key可通过区间扫描来寻找。在区间不大时候，需要扫描的range是有限的，性能方面也是非常快的。 文件可以进行压缩，我们只需要记录segment的start和end的key 如何实现： 在内存中引入排序结构，比如红黑树或者AVL-tree，在抵达threshold之后写入磁盘 查找的时候按照先内存后磁盘的方法进行搜寻 定时后台合并文件 为了支持崩溃恢复，可以为内存中的数据额外做一份普通的日志来作为恢复使用 3.1. LSM-Tree所有类似这种排序后的segment file合并的结构都可以称之LSM-Tree(Log-structured merge-tree)。 包括LevelDB,RocksDB和Cassandra，Hbase都有LSM-tree的影子。另外ES以来的Lucence索引引擎，也用了类似的逻辑：倒排索引按照key的顺序保存在文件中，通过额外的索引的索引来快速搜索这些倒排索引。 注意SSTable是索引，LSM-Tree是真正存储数据的文件结构。 3.2. 优化最坏情况下，如果某个key不存在或者key只存在最老的segment中时候，需要触发一次全segment文件的扫描操作。对于key不存在的情况，引入blooming filter，保证如果filter告诉你不存在，保证key确实不存在。 对于后者，SSTable的压缩和合并逻辑会有一些影响，有两种合并逻辑： 大吞小 分层合并：将旧的数据分到单独的层级，然后进行合并 4. B-TreeB-Tree将数据和索引分成固定大小的数据块，一般为4KB（配合x86的默认页大小4KB），然后将数据块们组织成树形结构。注意这里，B-Tree保存的是索引信息，每一个叶子节点保存了某个值的具体位置信息。 参考： B-Tree MySQL索引背后的数据结构及算法原理 简单来说，一个M维度的B-Tree节点可以如此描述： 123456struct Node &#123; int numberKeys; string keys[M - 1]; object values[M - 1]; struct Node children[M];&#125; 另外有一些约束来保证B-Tree的搜索性能，对于一棵order为m的树（最多有m个子节点）： 任何节点如果有k个key，那么就有k+1个ref 除了叶子节点，每一层至少是半满的，也就是至少有[m/2]个key和key+1的ref；最多有有m-1个key和m个ref 每个internal 节点至少有2个子节点（2个ref） 在这种情况下，整棵树的高度可以限制在(N为key的个数）： H = \\frac{log_{[m/2]}(N+1)}{2}注意一棵b树的每个节点既保存key对应的值，又保存了ref的信息。 4.1 B-Tree容错B-Tree一般使用预写日志(write-ahead, WAL)，先写日志，再写Tree。 多线程情况下， B-Tree不像LSM-Tree那么容易。 4.2 B-Tree优化 写时复制 B+ Tree，也就是在internal节点不保存具体节点的值，只保存ref或者其他索引信息；在叶子节点才保存具体的值。这样做的另外一个好处是可以把非叶子节点都加载到内存中。 slibing节点直接可以增加额外的ref来快速遍历 分形树（FTI，Fractal Tree Indexes） 为叶子节点增加存储数据的buffer，组织成一棵树 为节点增加Message buffer，用于缓冲读写请求 5. LSM-Tree和B-Tree比较写放大：合并数据时候引入的额外写入。 LSM-Tree优势： 有时候具有较低的写放大 顺序写人更加好的cache效率 更好的压缩和更少的碎片 LSM-Tree缺点： 后台合并操作影响前台读写性能，相对而言，B-Tree的性能更加稳定 高吞吐量时候，如果后台合并速度跟不上，磁盘空间最终会被吃完。 B-Tree更好的支持锁机制。在许多关系数据库中，事务隔离是通过key范围上的锁来实现的。 6.其他6.1. 二级索引除了主索引外的额外索引，但是会有key重复的问题。一般通过拼凑其他信息来使得key唯一。 6.2. 堆文件一般索引中不保存具体的值，只是保存一个ref信息或者位置信息，具体的内容保存在堆文件中。 在更新时候，如果新值不大于旧值，那么直接覆盖就可以了；否则需要重新分配空间，并且所有指向这个值的ref信息都需要更新或者留下一个指向新位置的间接跳转信息。 6.3. 聚集索引索引中直接保存具体的值。另外有保存部分值的覆盖索引或者包含列索引。（类似cache） 无论那种都可以提高读取性能，代价是复杂的插入和事务同步问题。 6.4. 多列索引对于多列进行合并索引。 级联索引 把多个列合并拼接起来作为一个key索引。对于A+B拼接的，可以对于A+B或者A进行快速索引，但是没有办法对B单独进行快速索引。 多维索引 对于多个列进行真正的索引。传统的B-Tree和LSM-Tree都没有办法高效的应对这种查询。 6.4.1. R-TreeR树是用来做空间数据存储的树状数据结构。例如给地理位置，矩形和多边形这类多维数据创建索引。 类似于B-Tree，R-Tree将空间划分成多个子空间（类似于一个range），然后继续划分直到最终值，效果如下： 与此相关的还有其他的名为空间索引的机制： 参考文章 https://cloud.tencent.com/developer/news/199266 https://zhuanlan.zhihu.com/p/38597148 空间索引列表： GeoHash kd-tree Grid index 四叉树/八叉树 Space filling curve：通过一条线来描述空间上的所有位置，二维值可以转化成单个值 LSH（Locality Sensitive Hashing 6.5. 全文搜索全文搜索不同于之前的索引有明显的范围。全文搜索往往是模糊的。 lucene通过给key构建前缀树来提供key的模糊搜索。 7. 内存数据库 随机访问 -&gt; 可以使用磁盘没有办法高效实用的数据结构 易失性 -&gt; NVM 标准产品： redis RAMCloud 8. 事务处理（OLTP，online transaction processing)OLTP类似于传统的SQL引擎，查询没有固定的format，更多是ad-hoc(online)的查询。OLAP（online analytic processing），类似于数据仓库。OLTP的索引更多使用上述提到的索引；OLAP需要新设计的索引。 Property Transaction processing systems (OLTP) Analytic systems (OLAP) Main read pattern |Small number of records per query, fetched by key |Aggregate over large number of recordsMain write pattern |Random-access, low-latency writes from user input |Bulk import (ETL) or event streamPrimarily used by |End user/customer, via web application |Internal analyst, for decision supportWhat data represents |Latest state of data (current point in time) |History of events that happened over timeDataset size |Gigabytes to terabytes |Terabytes to petabytes 典型的数据仓库 Terdata Vertica SAP HAHA Hadoop系列 9. 列式存储 按照列的方式来存储数据，而不是传统的整行的顺序 只需要关注几列 -&gt; 更少的数据读取和更快的读取速度 方便压缩 位图进一步的游程(Run-Length)编码 cache &amp; memory friend，并且可以使用SIMD指令 列式存储的排序和索引 HBase列簇中的数据式按照行来存储的。 10. Data Cubes and Materialized Views(物化视图)物化会提前计算出一些结果然后保存下来。Data Cube就是按照各种不同维度聚合形成的数据块。 优势是预先计算能获得好的性能提升。 劣势缺乏灵活性和额外的存储空间。","categories":[],"tags":[{"name":"Storage","slug":"Storage","permalink":"http://yoursite.com/tags/Storage/"},{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"系统设计","slug":"系统设计","permalink":"http://yoursite.com/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"name":"索引","slug":"索引","permalink":"http://yoursite.com/tags/%E7%B4%A2%E5%BC%95/"}]},{"title":"RSIC-V RV32I Instruction Set","slug":"RSIC-V-RV32I-Instruction-Set","date":"2019-11-18T14:28:50.000Z","updated":"2019-12-16T15:09:45.447Z","comments":true,"path":"2019/11/18/RSIC-V-RV32I-Instruction-Set/","link":"","permalink":"http://yoursite.com/2019/11/18/RSIC-V-RV32I-Instruction-Set/","excerpt":"","text":"1. Instruction LengthRISC-V指令是定长的32bit，但是拓展可以支持变长。变长一定是16bit的整数倍。 encoding convension要求所有32bit指令长度的命令最低两位一定是11. 注意RISC-V是小端的指令集。对于&gt;32bit长度的指令格式，同样要求满足这个要求，因此对于16bit指令长度，要求最低两位一定不是11。 当然对于non-standard指令格式，RISC-V可以是大端的。 2. RV32IRV32I是最基础的指令集，也是任何RISC-V实现必须实现的指令集。RV32I包括了47条独特指令，另外，实现可以选择使用总是trap的系统（SYSTEM）硬件指令代替 8 条 SCALL / SBREAK / RD* 指令，可以讲指令集减少到40条；如果还能够实现FENCE和FENC.I，那么可以将指令总数减少到38条。RV32I 能够模拟几乎所有的 ISA 扩展（除了 A 扩展，它需要额外的硬件来支持原子性（atomicity））。 RV32I was designed to be sufficient to form a compiler target and to support modern operating system environments. The ISA was also designed to reduce the hardware required in a minimal implementation. RV32I contains 47 unique instructions, though a simple implementation might cover the eight SCALL/SBREAK/CSRR* instructions with a single SYSTEM hardware instruction that always traps and might be able to implement the FENCE and FENCE.I instructions as NOPs, reducing hardware instruction count to 38 total. RV32I can emulate almost any other ISA extension (except the A extension, which requires additional hardware support for atomicity). RV32I包括了32个32bit的通用寄存器(x0-x31)外加一个用户可见的pc寄存器。32个通用寄存器其中x0固定为全0，x1一般用于保存返回值。详细的register convension参考较早文章。 2.1. opcode layoutRISC-V设计几个理念： 所有的layout格式尽量共享位置的意义的定义 比如所有的指令的r0，r1，rd位置都固定index 尽量减少指令额外的计算，比如预先进行shift，只使用符号扩展 RV32I包括了4种基本格式(R/I/S/U)和两种变化格式(B/J)： 可以看到寄存器的位置是固定的。 2.2. 整数指令首先需要注意到，opcode的长度是8个bit，去掉固定为11的最低两位，能用的opcode长度是6bit，也就是说最多支持2^6=64条指令。但实际上，RV32I中的很多指令是公用opcode的，通过额外参数来区分具体的action。 比如ADD和SUB就共享opcode。完整的列表如下： LUI: load imm into register AUIPC: add imm to pc JAL: unconditional direct jump JALR: unconditional indirect jump BEQ: conditional branch when equal BNE: conditional branch when not equal BLT: conditional branch when r1 &lt; r2 BGE: conditional branch when r1 &gt; r2 BLTU: conditional branch when r1 &lt; r2 as unsinged BGEU: conditional branch when r1 &gt; r2 as unsinged LB: load 8bit value from memory into register LH: load 16bit value from memory into register LW: load 32bit value from memory into register LBU: load 8bit unsigned value from memory into register LHU: load 16bit unsigned value from memory into register SB: store 8bit value from register to memory SH: store 16bit value from register to memory SW: store 32bit value from register to memory ADDI: adds the sign-extended 12-bit immediate with r1 to rd SLTI: put 1 into register if r1 &lt; signed extend imm otherwise 0 SLTIU: put 1 into register if r1 &lt; r2 extend imm as unsigned otherwise 0 XORI: xor the sign-extended 12-bit immediate with r1 to rd ORI: or the sign-extended 12-bit immediate with r1 to rd ANDI: and the sign-extended 12-bit immediate with r1 to rd SLLI: logical left shift register value imm bits SRLI: logical right shift register value imm bits SRAI: arithmetic right shift register value imm bitsshift ADD: add SUB: sub SLL: logical left shift r1 value low 5 bits value of r2 SLT: put 1 into register if r1 &lt; r2 otherwise 0 SLTU: put 1 into register if r1 &lt; r2 as unsignedotherwise 0 XOR: xor SRL: logical right shift r1 value low 5 bits value of r2 SRA: arithmetic right shift r1 value low 5 bits value of r2 OR: or AND: and FENCE: memory fence ECALL：Trap to System Call EBREAK: DEBUG mode break 一些注解 RISC-V的FENCE可以玩组合: Any combination of device input (I), device output (O), memory reads (R), and memory writes (W) may be ordered with respect to any combination of the same. RISC-V是没有Overflow Flag: 下面引自官方文档： We did not include special instruction-set support for overflow checks on integer arithmetic operations in the base instruction set, as many overflow checks can be cheaply implemented using RISC-V branches. Overflow checking for unsigned addition requires only a single additional branch instruction after the addition: add t0, t1, t2; bltu t0, t1, overflow. For signed addition, if one operand’s sign is known, overflow checking requires only a single branch after the addition: addi t0, t1, +imm; blt t0, t1, overflow. This covers the common case of addition with an immediate operand. For general signed addition, three additional instructions after the addition are required, leveraging the observation that the sum should be less than one of the operands if and only if the other operand is negative. 1234add t0, t1, t2slti t3, t2, 0slt t4, t0, t1bne t3, t4, overflow In RV64I, checks of 32-bit signed additions can be optimized further by comparing the results of ADD and ADDW on the operands. 简单来说，检查是否overflow没有flag给你用（为了简化电路设计，另外overflow用处不大），而是用指令+branch来进行判断，详细而言分成3中情况： unsigned相加，那么没有overflow意味着 rd &gt; r1 &amp;&amp; rd &gt; r2，当然对于imm版本只需要检测rd &gt; r1 signed imm相加，如果imm符号知道，那么判断rd &gt; r1或者rd &lt; r1 剩下的就需要好几条指令来判断了 NOP命令: 不存在的，可以用ADD r1, r1, r0来代替。拓展指令集可能加入单独的NOP指令。 状态寄存器: 不存在的+1。老版本的文档将CSR相关命令列到RV32I下面；当前文档(draft-20191114-0777770)单独拆到了一章：“Zicsr”, Control and Status Register(CSR) Instructions, Version 2.0 因此也不存在用于比较的EFLAGS，所有的条件跳转都是比较具体的两个寄存器或者寄存器和imm的值。 说到底也是为了简化系统的设计。 3. RV64I和RV64I非常类似，差别在于： 寄存器宽度变成了64bit 扩展了64bit宽度的指令LD/SD (double word) 增加了单独处理32bit的指令(ADD之类的现在等是64bit的) ADDIW/SLLW/SRLW/SUBW/SRAW 注意移位操作offset bits还是5bit 移位操作的offset bits因为64bit=32bit*2，从5bit”升级”成6bit 其实RV128I指令集的拓展也类似，理论上可以拓展到imm无法支持offset bits的描述，但在此之前，量子计算机应该出来吧。 Reference https://content.riscv.org/wp-content/uploads/2017/05/riscv-spec-v2.2.pdf risc-v manual: https://github.com/riscv/riscv-isa-manual http://gfiles.chinaaet.com/scorpio/group/20170425/4000264810-6362872848946855461428672.pdf","categories":[],"tags":[{"name":"Micro,RISC-V,ISA","slug":"Micro-RISC-V-ISA","permalink":"http://yoursite.com/tags/Micro-RISC-V-ISA/"}]},{"title":"野猪书第二章读书笔记","slug":"wild-pig-chapter2","date":"2019-11-18T08:33:11.000Z","updated":"2019-11-18T08:34:25.400Z","comments":true,"path":"2019/11/18/wild-pig-chapter2/","link":"","permalink":"http://yoursite.com/2019/11/18/wild-pig-chapter2/","excerpt":"","text":"1. 模型 层次化模型(hierachy) 树状结构 -&gt; keep one-to-many or many-to-one no many-to-many 关系化模型 -&gt; sql 范式 在复杂的或者多层的one-to-many结构中需要拆成多张表 文档化模型(document) -&gt; json 一列中可以保存复杂结构的数据 比如列表形式的历史记录 对于不复杂的one-to-many特别适合 但是对于many-to-many不是那么有优势 join不是那么友好，许多数据库都不支持join 网络化模型(network) 图状结构,many-to-many 搜索和优化变得困难 图计算数据库 2. 存储模型规格化的（normalized): 所有重复的数值(主要是string)会被应设成id 统一的格式和语法 避免歧义 i18n的时候分离了显示和存储要求，更加方便迁移 更快的search [坏处]规格化的数据需要多张表，search时候需要更加多的join 非规格化的(denormalized): 如果数据库本身不支持join 可能对于cache hit更加友好 3. schema设计 读时schema模式（所谓无模式）：在读的时候检查需要的shchema是否合理 写时schema模式，在写的时候做检查，否则不让写入 实际上会是混合模式，写时会做一部分，读的时候做一部分。 这些设计在column发生修改时候变的有所不同。 读时schema可能只需要写入新的field的值就可以了： 123if (user &amp;&amp; user.name &amp;&amp; !user.first_name) &#123; user.first_name = user.name.split(&quot; &quot;)[0]&#125; 写时schema需要更新数据库table的schema 123ALTER TABLE users ADD COLUMN first_name text;UPDATE users SET first_name = split_part(name, &quot; &quot;, 1); -- PostgreSQLUPDATE users SET first_name = substring_index(name, &quot; &quot;, 1); -- MySQL schema的更新(ALTER)是件代价不小的操作，另外UPDATE操作对于大表和有复杂关联的表系列也有不小的代价。一般而言可以将新加入的field设置为NULL，在读的时候进行设置。 所以在这种情况下，如果数据中包含了不一致的schema结构（数据异构），例如： 有许多的数据格式 数据系统的schema结构不稳定，会发生变动 4. 查询的局部性 分成多张表的数据存储格式在读取连续数据时候会有一定的性能影响，需要多次索引 修改数据时候，最好的是原地覆盖，因此建议写入的文档尽量小，并且不增加数据大小 所以，为了提高局部性，可以 父表内嵌入子表数据（类似json） 多索引集群表 列式存储，列簇 5. 数据查询语言 声明式：比如SQL，只是给出了我想要什么，给出范围，但是没有给出具体的操作流程 命令式：定义为完整的操作流程，执行的命令。 声明式隔离了底层的实现逻辑，使得： API变的简洁和容易理解 提供优化的机会 提供并行执行的实现方式 6. 图状数据库 基本组成”顶点” + “边”。 相关算法：导航，PageRank 图状数据库模型： 属性图（property graph） Neon4j, Titan和InfiniteGraph 三元存储模型（triple-store） Datomic, AllegroGraph 查询语句 声明式查询语句：Cypher, SPARQL, Datalog 命令式查询语句：Gremlin 图处理框架: Pregel 6.1. 属性图在属性图模型中，一个顶点包含了： UUID Input/Output edge list property set (key-value pair) 一个边包含了： UUID edage start/end node label describe relationship between start node and end node property set (key-value pair) 在完成这些定义后，属性图可以很方便的使用多张关系数据库表来进行存储 12345678910111213CREATE TABLE vertices ( vertex_id integer PRIMARY KEY, properties json);CREATE TABLE edges ( edge_id integer PRIMARY KEY, tail_vertex integer REFERENCES vertices (vertex_id), head_vertex integer REFERENCES vertices (vertex_id), label text, properties json);CREATE INDEX edges_tails ON edges (tail_vertex);CREATE INDEX edges_heads ON edges (head_vertex); 属性图提供了非常强大的灵活性来描述一张图的结构。 6.2. Cypher基本思路是定义一个节点或者一条边需要满足的条件，查询的具体细节不关注，比如，我们想要查询这一样一个节点（人）： person，通过节点label为BORN_IN的outgoing edge，以及系列WITH_IN outgoing edage，最终抵达某个标注为US的节点 person，通过节点label为LIVES_IN的outgoing edge，以及系列WITH_IN outgoing edage，抵达某个标注为US的节点 最后打印出来person的名字： 1234MATCH (person) -[:BORN_IN]-&gt; () -[:WITHIN*0..]-&gt; (us:Location &#123;name:&apos;United States&apos;&#125;), (person) -[:LIVES_IN]-&gt; () -[:WITHIN*0..]-&gt; (eu:Location &#123;name:&apos;Europe&apos;&#125;)RETURN person.name 如果用SQL来做，会成多次的表的join。 123456789101112131415161718192021222324252627282930313233343536373839WITH RECURSIVE -- in_usa is the set of vertex IDs of all locations within the United States in_usa(vertex_id) AS ( SELECT vertex_id FROM vertices WHERE properties-&gt;&gt;'name' = 'United States' UNION SELECT edges.tail_vertex FROM edges JOIN in_usa ON edges.head_vertex = in_usa.vertex_id WHERE edges.label = 'within' ), -- in_europe is the set of vertex IDs of all locations within Europe in_europe(vertex_id) AS ( SELECT vertex_id FROM vertices WHERE properties-&gt;&gt;'name' = 'Europe' UNION SELECT edges.tail_vertex FROM edges JOIN in_europe ON edges.head_vertex = in_europe.vertex_id WHERE edges.label = 'within' ), -- born_in_usa is the set of vertex IDs of all people born in the US born_in_usa(vertex_id) AS ( SELECT edges.tail_vertex FROM edges JOIN in_usa ON edges.head_vertex = in_usa.vertex_id WHERE edges.label = 'born_in' ), -- lives_in_europe is the set of vertex IDs of all people living in Europe lives_in_europe(vertex_id) AS ( SELECT edges.tail_vertex FROM edges JOIN in_europe ON edges.head_vertex = in_europe.vertex_id WHERE edges.label = 'lives_in' ) SELECT vertices.properties-&gt;&gt;'name'FROM vertices-- join to find those people who were both born in the US *and* live in EuropeJOIN born_in_usa ON vertices.vertex_id = born_in_usa.vertex_idJOIN lives_in_europe ON vertices.vertex_id = lives_in_europe.vertex_id; 6.3. 三元存储模型（triple-store）三元存储模型和属性图类似，但是颗粒度更加细。所有的描述都是一个三维的tuple： (subject, predicate, object). subject一定是某个节点 predicate是一个edge或者一个属性 object可以是一个节点（edge）或者一个属性值（属性） 比如，可以这样来描述一张图： 123456789101112131415@prefix : &lt;urn:example:&gt;._:lucy a :Person._:lucy :name &quot;Lucy&quot;._:lucy :bornIn _:idaho._:idaho a :Location._:idaho :name &quot;Idaho&quot;._:idaho :type &quot;state&quot;._:idaho :within _:usa._:usa a :Location._:usa :name &quot;United States&quot;._:usa :type &quot;country&quot;._:usa :within _:namerica._:namerica a :Location._:namerica :name &quot;North America&quot;._:namerica :type &quot;continent&quot;. 可以压缩一下： 12345@prefix : &lt;urn:example:&gt;._:lucy a :Person; :name &quot;Lucy&quot;; :bornIn _:idaho._:idaho a :Location; :name &quot;Idaho&quot;; :type &quot;state&quot;; :within _:usa._:usa a :Location; :name &quot;United States&quot;; :type &quot;country&quot;; :within _:namerica._:namerica a :Location; :name &quot;North America&quot;; :type &quot;continent&quot;. 7. 其他模型 针对DNA（只有四个值）的基因组数据，GenBank 针对海量数据数据库 针对全文搜索的数据库","categories":[],"tags":[]},{"title":"RISC-V 寄存器 overview","slug":"RISC-V-寄存器-overview","date":"2019-11-16T16:11:47.000Z","updated":"2019-11-17T02:24:52.238Z","comments":true,"path":"2019/11/17/RISC-V-寄存器-overview/","link":"","permalink":"http://yoursite.com/2019/11/17/RISC-V-%E5%AF%84%E5%AD%98%E5%99%A8-overview/","excerpt":"","text":"1. OverviewRISC-V顾名思义是一个RISC指令集，有一些特性（特别和x86相比）： 大量的寄存器 固定为0的寄存器(x0): “零寄存器”（zero register，注：其值永远为零） 非load和save指令不能访问内存，只能在寄存器间操作 不提供context save和restore的命令 所有指令都是固定长度的32bit 指令长度固定32bit使得处理64bit的立即数，一定至少要两条指令。 1.1. 指令集和拓展RISC-V指令集最基本的指令只包含integer instruction，包括RV32I和RV64I。其中RV32I是社区声明过已经冻结修改的。（其实RV64I算是拓展，而且也被冻结了） 具体的指令情况如下（来自维基百科）： 指令集名称 描述 版本 状态 基本指令集 RV32I 基本整数指令集, 32位 2.0 冻结 RV32E 基本整数指令集(嵌入式系统), 32位, 16 寄存器 1.9 开放 RV64I 基本整数指令集, 64位 2.0 冻结 RV128I 基本整数指令集, 128位 1.7 开放 标准扩展指令集 M|整数乘除法标准扩展|2.0|冻结A|不可中断指令(Atomic)标准扩展|2.0|冻结F|单精确度浮点运算标准扩展|2.0|冻结D|双倍精确度浮点运算标准扩展|2.0|冻结G|所有以上的扩展指令集以及基本指令集的总和的简称|不适用|不适用Q|四倍精确度浮点运算标准扩展|2.0|冻结L|十进制浮点运算标准扩展|0.0|开放C|压缩指令标准扩展|2.0|冻结B|位操作标准扩展|0.36|开放J|动态指令翻译标准扩展|0.0|开放T|顺序存储器访问标准扩展|0.0|开放P|单指令多数据流（SIMD）运算标准扩展|0.1|开放V|向量运算标准扩展|0.2|开放N|用户中断标准扩展|1.1|开放 2. Register基础的寄存器包括32个整数寄存器（嵌入式版本是16个整数寄存器），也就是RV32I的寄存器，x0-x31。其中x0是固定为0的寄存器，而因为寄存器够用，所以没有单独的Stack寄存器。 引入RV32F和RV32D会引入32个浮点寄存器，f0-f31。 RISC-V的ABI中定义了各个寄存器的calling convension： Register ABI Name Description Saver x0| zero |Hard-wired zero |—x1 |ra |Return address |Callerx2 |sp |Stack pointer |Calleex3 |gp |Global pointer |—x4 |tp |Thread pointer |—x5–7 |t0–2 |Temporaries |Callerx8 |s0/fp |Saved register/frame pointer |Calleex9 |s1 |Saved register |Calleex10–11 |a0–1 |Function arguments/return values |Callerx12–17 |a2–7 |Function arguments |Callerx18–27 |s2–11 |Saved registers |Calleex28–31 |t3–6 |Temporaries |Callerf0–7 |ft0–7 |FP temporaries |Callerf8–9 |fs0–1 |FP saved registers |Calleef10–11 |fa0–1 |FP arguments/return values |Callerf12–17 |fa2–7 |FP arguments |Callerf18–27 |fs2–11 |FP saved registers |Calleef28–31 |ft8–11 |FP temporaries |Caller Reference参考： RISC-V 手册 维基百科: RISC-V 关于RISC-V你所需要知道的一切 Github","categories":[],"tags":[{"name":"Micro","slug":"Micro","permalink":"http://yoursite.com/tags/Micro/"},{"name":"RISC-V","slug":"RISC-V","permalink":"http://yoursite.com/tags/RISC-V/"}]},{"title":"ARM ISA Overview","slug":"ARM-Register-Quick-View","date":"2019-11-14T09:23:35.000Z","updated":"2019-11-27T11:53:41.530Z","comments":true,"path":"2019/11/14/ARM-Register-Quick-View/","link":"","permalink":"http://yoursite.com/2019/11/14/ARM-Register-Quick-View/","excerpt":"","text":"1. 指令ARM中能看到的指令集包括： thumb: 16bit的指令集 thumb-2: thumb的升级版，16bit/32bit混合指令集 arm: 32bit的指令集 A32: ARMv8中的arm指令集 T32: ARMv8中的thumb-2指令集，同时包含一些拓展 A64: ARMv8的64bit的指令集 Neon: ARM的SIMD指令集 ARMv8支持两种state： AArch64: 使用A64指令集，一种32bit fix length的指令集 支持31个64bit的通用寄存器 使用64bit的PC和SP寄存器 支持32个128bit的SIMD寄存器 AArch32: 支持A32或者T32指令集 支持32个32bit的通用寄存器 使用32bit的PC和SP寄存器 支持32个64bit的SIMD寄存器 注意的是ARMv8的A32和T32向前兼容的同时，还包括了其他一些拓展。 2. ARM ProfileARM系列一般都能看到A，R和M系列，分别代表着：普通应用，实时计算和移动处理的三种不同的需求。 具体以ARMv8为例子，下面摘自ARM的官方文档： A Application profile: Supports a Virtual Memory System Architecture (VMSA) based on a Memory Management Unit (MMU). Supports the A64, A32, and T32 instruction sets. R Real-time profile: Supports a Protected Memory System Architecture (PMSA) based on a Memory Protection Unit (MPU).-Supports the A32 and T32 instruction sets. M Microcontroller profile, described in this manual: Implements a programmers’ model designed for low-latency interrupt processing, with hardware stacking of registers and support for writing interrupt handlers in high-level languages. Optionally implements a variant of the R-profile PMSA. Supports a variant of the T32 instruction set. 3. LLVM ARMv7 Register我们可以在lib/target/ARM/ARMRegisterInfo.td中找到所有寄存器的定义： 1234567891011121314// Registers are identified with 4-bit ID numbers.class ARMReg&lt;bits&lt;16&gt; Enc, string n, list&lt;Register&gt; subregs = [], list&lt;string&gt; altNames = []&gt; : Register&lt;n, altNames&gt; &#123; let HWEncoding = Enc; let Namespace = &quot;ARM&quot;; let SubRegs = subregs; // All bits of ARM registers with sub-registers are covered by sub-registers. let CoveredBySubRegs = 1;&#125;class ARMFReg&lt;bits&lt;16&gt; Enc, string n&gt; : Register&lt;n&gt; &#123; let HWEncoding = Enc; let Namespace = &quot;ARM&quot;;&#125; 上述是两个基类，定义了整数寄存器和浮点寄存器的基类。总结来说，ARMv7的数据存储寄存器包括： r1-r12 32bit integer register pc, lr, sp 32bit integer register q0-q16 128bit integer register sub-reg: d0-d15 64bit float register sub-reg: s0-s31 32bit float register sub-reg: d16-d31 64bit float regiter 一般而言，有些寄存器有固定/约定的用处： pc == Program Counter lr == Link Register sp == Stack Pointer r12 == ip (scratch) r7 == Frame Pointer (thumb-style backtraces) r9 == May be reserved as Thread Register r11 == Frame Pointer (arm-style backtraces) r10 == Stack Limit 另外还有一系列控制寄存器，以下仅举例后续用到再做分析。除了APSR，大部分其他控制寄存器都是要在非用户模式下才能操作： Program Status Register APSR: Application Program Status Register, 32bit integer register 类似与x86的EFLAGs，用于记录condition flag。 CPSR: Current Program Status Register, 32bit integer register 似乎CPSR是APSR的alias。在用户模式叫APSR，在其他模式叫CPSR。 SPSR: Saved Program Status Register, 32bit integer register 仅在非用户模式下使用，用于保存CPSR的信息，方便跳转回来时候回复环境。 FPSCR: Floating-Point Status and Control Register, 32bit integer register 浮点状态寄存器。 Float Special Registe(Only privileged mode) FPSID: Floating-Point System ID Register, 32bit integer register 浮点系统设置寄存器，用来表明NEON/VFP等实现是否被使用。 FPEXC: Floating-point Exception Register, 32bit integer register 用于表明在exception时候如何处理，特别是在NEON/VFP模式下面。 FPINST and FPINST2Floating-Point Instruction Registers, 32bit integer register ITSTATE: Thumb if-then指令状态寄存器。 3.1. 通用寄存器定义 r0 - r15 12345678910111213141516171819202122// Integer registersdef R0 : ARMReg&lt; 0, &quot;r0&quot;&gt;, DwarfRegNum&lt;[0]&gt;;def R1 : ARMReg&lt; 1, &quot;r1&quot;&gt;, DwarfRegNum&lt;[1]&gt;;def R2 : ARMReg&lt; 2, &quot;r2&quot;&gt;, DwarfRegNum&lt;[2]&gt;;def R3 : ARMReg&lt; 3, &quot;r3&quot;&gt;, DwarfRegNum&lt;[3]&gt;;def R4 : ARMReg&lt; 4, &quot;r4&quot;&gt;, DwarfRegNum&lt;[4]&gt;;def R5 : ARMReg&lt; 5, &quot;r5&quot;&gt;, DwarfRegNum&lt;[5]&gt;;def R6 : ARMReg&lt; 6, &quot;r6&quot;&gt;, DwarfRegNum&lt;[6]&gt;;def R7 : ARMReg&lt; 7, &quot;r7&quot;&gt;, DwarfRegNum&lt;[7]&gt;;// These require 32-bit instructions.let CostPerUse = 1 in &#123; // extra cost when usingdef R8 : ARMReg&lt; 8, &quot;r8&quot;&gt;, DwarfRegNum&lt;[8]&gt;;def R9 : ARMReg&lt; 9, &quot;r9&quot;&gt;, DwarfRegNum&lt;[9]&gt;;def R10 : ARMReg&lt;10, &quot;r10&quot;&gt;, DwarfRegNum&lt;[10]&gt;;def R11 : ARMReg&lt;11, &quot;r11&quot;&gt;, DwarfRegNum&lt;[11]&gt;;def R12 : ARMReg&lt;12, &quot;r12&quot;&gt;, DwarfRegNum&lt;[12]&gt;;let RegAltNameIndices = [RegNamesRaw] in &#123; // 定义别名def SP : ARMReg&lt;13, &quot;sp&quot;, [], [&quot;r13&quot;]&gt;, DwarfRegNum&lt;[13]&gt;;def LR : ARMReg&lt;14, &quot;lr&quot;, [], [&quot;r14&quot;]&gt;, DwarfRegNum&lt;[14]&gt;;def PC : ARMReg&lt;15, &quot;pc&quot;, [], [&quot;r15&quot;]&gt;, DwarfRegNum&lt;[15]&gt;;&#125;&#125; q0 - q15 q系列的寄存器包含了一系列的子寄存器，因此需要一系列的SubRegisterIndex来定义他们的关系： 12def dsub_0 : SubRegIndex&lt;64&gt;;def dsub_1 : SubRegIndex&lt;64, 64&gt;; 第一条描述了qx中的d(2x)index：从0开始，长度为64bit；第二条描述了d(2x+1)index：从64bit开始，长度64bit。 123456789101112131415161718192021// Advanced SIMD (NEON) defines 16 quad-word aliaseslet SubRegIndices = [dsub_0, dsub_1] in &#123;def Q0 : ARMReg&lt; 0, &quot;q0&quot;, [D0, D1]&gt;;def Q1 : ARMReg&lt; 1, &quot;q1&quot;, [D2, D3]&gt;;def Q2 : ARMReg&lt; 2, &quot;q2&quot;, [D4, D5]&gt;;def Q3 : ARMReg&lt; 3, &quot;q3&quot;, [D6, D7]&gt;;def Q4 : ARMReg&lt; 4, &quot;q4&quot;, [D8, D9]&gt;;def Q5 : ARMReg&lt; 5, &quot;q5&quot;, [D10, D11]&gt;;def Q6 : ARMReg&lt; 6, &quot;q6&quot;, [D12, D13]&gt;;def Q7 : ARMReg&lt; 7, &quot;q7&quot;, [D14, D15]&gt;;&#125;let SubRegIndices = [dsub_0, dsub_1] in &#123;def Q8 : ARMReg&lt; 8, &quot;q8&quot;, [D16, D17]&gt;;def Q9 : ARMReg&lt; 9, &quot;q9&quot;, [D18, D19]&gt;;def Q10 : ARMReg&lt;10, &quot;q10&quot;, [D20, D21]&gt;;def Q11 : ARMReg&lt;11, &quot;q11&quot;, [D22, D23]&gt;;def Q12 : ARMReg&lt;12, &quot;q12&quot;, [D24, D25]&gt;;def Q13 : ARMReg&lt;13, &quot;q13&quot;, [D26, D27]&gt;;def Q14 : ARMReg&lt;14, &quot;q14&quot;, [D28, D29]&gt;;def Q15 : ARMReg&lt;15, &quot;q15&quot;, [D30, D31]&gt;;&#125; 可以看到这里的let SubRegIndices = [dsub_0, dsub_1]。 3.2. 控制寄存器的定义相对没有什么花头，简单的定义，略掉一些。 12345678910111213141516// Current Program Status Register.// We model fpscr with two registers: FPSCR models the control bits and will be// reserved. FPSCR_NZCV models the flag bits and will be unreserved. APSR_NZCV// models the APSR when it&apos;s accessed by some special instructions. In such cases// it has the same encoding as PC.def CPSR : ARMReg&lt;0, &quot;cpsr&quot;&gt;;def APSR : ARMReg&lt;15, &quot;apsr&quot;&gt;;def APSR_NZCV : ARMReg&lt;15, &quot;apsr_nzcv&quot;&gt;;def SPSR : ARMReg&lt;2, &quot;spsr&quot;&gt;;def FPSCR : ARMReg&lt;3, &quot;fpscr&quot;&gt;;def FPSCR_NZCV : ARMReg&lt;3, &quot;fpscr_nzcv&quot;&gt; &#123; let Aliases = [FPSCR];&#125;def ITSTATE : ARMReg&lt;4, &quot;itstate&quot;&gt;;... 唯一可以注意的是，为了一些操作方便，这里对于NZCV的flags做了alias的定义。 3.3. 定义RegisterClass随后需要告诉LLVM如何使用这些寄存器，或者说哪些寄存器是一类的。比如，对于通用寄存器的定义： 1234567891011121314151617181920212223242526def GPR : RegisterClass&lt;&quot;ARM&quot;, [i32], 32, (add (sequence &quot;R%u&quot;, 0, 12), SP, LR, PC)&gt; &#123; // Allocate LR as the first CSR since it is always saved anyway. // For Thumb1 mode, we don&apos;t want to allocate hi regs at all, as we don&apos;t // know how to spill them. If we make our prologue/epilogue code smarter at // some point, we can go back to using the above allocation orders for the // Thumb1 instructions that know how to use hi regs. let AltOrders = [(add LR, GPR), (trunc GPR, 8), (add (trunc GPR, 8), R12, LR, (shl GPR, 8))]; let AltOrderSelect = [&#123; return MF.getSubtarget&lt;ARMSubtarget&gt;().getGPRAllocationOrder(MF); &#125;]; let DiagnosticString = &quot;operand must be a register in range [r0, r15]&quot;;&#125;// GPRs without the PC. Some ARM instructions do not allow the PC in// certain operand slots, particularly as the destination. Primarily// useful for disassembly.def GPRnopc : RegisterClass&lt;&quot;ARM&quot;, [i32], 32, (sub GPR, PC)&gt; &#123; let AltOrders = [(add LR, GPRnopc), (trunc GPRnopc, 8), (add (trunc GPRnopc, 8), R12, LR, (shl GPRnopc, 8))]; let AltOrderSelect = [&#123; return MF.getSubtarget&lt;ARMSubtarget&gt;().getGPRAllocationOrder(MF); &#125;]; let DiagnosticString = &quot;operand must be a register in range [r0, r14]&quot;;&#125; 这里定义了： class包含了哪些寄存器 选择的顺序 diagnostic信息 4. LLVM ARMv8 RegisterARMv8的通用寄存器升级到了64bit，包含了 X0-X31, 最后三个为FR,LR,SR,XZR sub-register：所有X寄存器的低32bit定义为：W0-W31，最后两个为WSP,WZR V0-V31, 类似于ARMv7中的Q0-Q31, 增加了一倍的浮点寄存器 d,s和ARMv7一致，额外增加了8bit的b类型寄存器 v是用来引用新增的vector model的。 EFLAGS被单独移出去了，更加详细控制寄存器信息，等到对应的命令时候再描述。 4.1. 通用寄存器定义12345678910111213141516171819202122232425262728def W0 : AArch64Reg&lt;0, &quot;w0&quot; &gt;, DwarfRegNum&lt;[0]&gt;;def W1 : AArch64Reg&lt;1, &quot;w1&quot; &gt;, DwarfRegNum&lt;[1]&gt;;def W2 : AArch64Reg&lt;2, &quot;w2&quot; &gt;, DwarfRegNum&lt;[2]&gt;;def W3 : AArch64Reg&lt;3, &quot;w3&quot; &gt;, DwarfRegNum&lt;[3]&gt;;def W4 : AArch64Reg&lt;4, &quot;w4&quot; &gt;, DwarfRegNum&lt;[4]&gt;;def W5 : AArch64Reg&lt;5, &quot;w5&quot; &gt;, DwarfRegNum&lt;[5]&gt;;...def W28 : AArch64Reg&lt;28, &quot;w28&quot;&gt;, DwarfRegNum&lt;[28]&gt;;def W29 : AArch64Reg&lt;29, &quot;w29&quot;&gt;, DwarfRegNum&lt;[29]&gt;;def W30 : AArch64Reg&lt;30, &quot;w30&quot;&gt;, DwarfRegNum&lt;[30]&gt;;def WSP : AArch64Reg&lt;31, &quot;wsp&quot;&gt;, DwarfRegNum&lt;[31]&gt;;def WZR : AArch64Reg&lt;31, &quot;wzr&quot;&gt;, DwarfRegAlias&lt;WSP&gt;;let SubRegIndices = [sub_32] in &#123;def X0 : AArch64Reg&lt;0, &quot;x0&quot;, [W0]&gt;, DwarfRegAlias&lt;W0&gt;;def X1 : AArch64Reg&lt;1, &quot;x1&quot;, [W1]&gt;, DwarfRegAlias&lt;W1&gt;;def X2 : AArch64Reg&lt;2, &quot;x2&quot;, [W2]&gt;, DwarfRegAlias&lt;W2&gt;;def X3 : AArch64Reg&lt;3, &quot;x3&quot;, [W3]&gt;, DwarfRegAlias&lt;W3&gt;;def X4 : AArch64Reg&lt;4, &quot;x4&quot;, [W4]&gt;, DwarfRegAlias&lt;W4&gt;;def X5 : AArch64Reg&lt;5, &quot;x5&quot;, [W5]&gt;, DwarfRegAlias&lt;W5&gt;;...def X24 : AArch64Reg&lt;24, &quot;x24&quot;, [W24]&gt;, DwarfRegAlias&lt;W24&gt;;def X28 : AArch64Reg&lt;28, &quot;x28&quot;, [W28]&gt;, DwarfRegAlias&lt;W28&gt;;def FP : AArch64Reg&lt;29, &quot;x29&quot;, [W29]&gt;, DwarfRegAlias&lt;W29&gt;;def LR : AArch64Reg&lt;30, &quot;x30&quot;, [W30]&gt;, DwarfRegAlias&lt;W30&gt;;def SP : AArch64Reg&lt;31, &quot;sp&quot;, [WSP]&gt;, DwarfRegAlias&lt;WSP&gt;;def XZR : AArch64Reg&lt;31, &quot;xzr&quot;, [WZR]&gt;, DwarfRegAlias&lt;WSP&gt;;&#125; 没有什么特别的。 4.2. SIMD &amp; FP寄存器普通的定义没有什么特别，只是加了一个b寄存器。 123456789101112131415161718192021222324252627def B0 : AArch64Reg&lt;0, &quot;b0&quot;&gt;, DwarfRegNum&lt;[64]&gt;;...def B31 : AArch64Reg&lt;31, &quot;b31&quot;&gt;, DwarfRegNum&lt;[95]&gt;;let SubRegIndices = [bsub] in &#123;def H0 : AArch64Reg&lt;0, &quot;h0&quot;, [B0]&gt;, DwarfRegAlias&lt;B0&gt;;...def H31 : AArch64Reg&lt;31, &quot;h31&quot;, [B31]&gt;, DwarfRegAlias&lt;B31&gt;;&#125;let SubRegIndices = [hsub] in &#123;def S0 : AArch64Reg&lt;0, &quot;s0&quot;, [H0]&gt;, DwarfRegAlias&lt;B0&gt;;...def S31 : AArch64Reg&lt;31, &quot;s31&quot;, [H31]&gt;, DwarfRegAlias&lt;B31&gt;;&#125;let SubRegIndices = [ssub], RegAltNameIndices = [vreg, vlist1] in &#123;def D0 : AArch64Reg&lt;0, &quot;d0&quot;, [S0], [&quot;v0&quot;, &quot;&quot;]&gt;, DwarfRegAlias&lt;B0&gt;;...def D31 : AArch64Reg&lt;31, &quot;d31&quot;, [S31], [&quot;v31&quot;, &quot;&quot;]&gt;, DwarfRegAlias&lt;B31&gt;;&#125;let SubRegIndices = [dsub], RegAltNameIndices = [vreg, vlist1] in &#123;def Q0 : AArch64Reg&lt;0, &quot;q0&quot;, [D0], [&quot;v0&quot;, &quot;&quot;]&gt;, DwarfRegAlias&lt;B0&gt;;...def Q31 : AArch64Reg&lt;31, &quot;q31&quot;, [D31], [&quot;v31&quot;, &quot;&quot;]&gt;, DwarfRegAlias&lt;B31&gt;;&#125; SubRegisterIndex定义不再赘述。注意这里sub-register再一个parent-register没有两个了，因为通用寄存器本身翻倍了。 4.3. Register Vector定义有意思的是LLVM是如何定义ARMv8中的vector value的使用的。 首先需要看到的是LLVM对于value type的定义，在LLVM/include/Target/ValueTypes.td中： 12345678910111213...def v8i16 : ValueType&lt;128, 38&gt;; // 8 x i16 vector valuedef v16i16 : ValueType&lt;256, 39&gt;; // 16 x i16 vector valuedef v32i16 : ValueType&lt;512, 40&gt;; // 32 x i16 vector valuedef v64i16 : ValueType&lt;1024,41&gt;; // 64 x i16 vector valuedef v128i16: ValueType&lt;2048,42&gt;; //128 x i16 vector valuedef v1i32 : ValueType&lt;32 , 43&gt;; // 1 x i32 vector valuedef v2i32 : ValueType&lt;64 , 44&gt;; // 2 x i32 vector valuedef v3i32 : ValueType&lt;96 , 45&gt;; // 3 x i32 vector valuedef v4i32 : ValueType&lt;128, 46&gt;; // 4 x i32 vector valuedef v5i32 : ValueType&lt;160, 47&gt;; // 5 x i32 vector value... 这些ValueType会被用在定义RegisterClass时候： 123456789101112131415def FPR64 : RegisterClass&lt;&quot;AArch64&quot;, [f64, i64, v2f32, v1f64, v8i8, v4i16, v2i32, v1i64, v4f16], 64, (sequence &quot;D%u&quot;, 0, 31)&gt;;// We don&apos;t (yet) have an f128 legal type, so don&apos;t use that here. We// normalize 128-bit vectors to v2f64 for arg passing and such, so use// that here.def FPR128 : RegisterClass&lt;&quot;AArch64&quot;, [v16i8, v8i16, v4i32, v2i64, v4f32, v2f64, f128, v8f16], 128, (sequence &quot;Q%u&quot;, 0, 31)&gt;;// The lower 16 vector registers. Some instructions can only take registers// in this range.def FPR128_lo : RegisterClass&lt;&quot;AArch64&quot;, [v16i8, v8i16, v4i32, v2i64, v4f32, v2f64, v8f16], 128, (trunc FPR128, 16)&gt;;","categories":[],"tags":[{"name":"LLVM","slug":"LLVM","permalink":"http://yoursite.com/tags/LLVM/"},{"name":"Micro","slug":"Micro","permalink":"http://yoursite.com/tags/Micro/"},{"name":"ARM","slug":"ARM","permalink":"http://yoursite.com/tags/ARM/"}]},{"title":"野猪书第一章读书笔记","slug":"wild-pig-chapter1","date":"2019-11-12T15:02:48.000Z","updated":"2019-12-16T15:09:50.479Z","comments":true,"path":"2019/11/12/wild-pig-chapter1/","link":"","permalink":"http://yoursite.com/2019/11/12/wild-pig-chapter1/","excerpt":"","text":"数据密集型应用系统 数据库 高速缓存 索引 流式处理 批处理 这里比较有意思的是索引，一般而言，索引不会单独领出来说，往往集成在数据库中。但实际上索引也许可以单独作为一个组件存在。而这些组件往往也不是独立存在，比如Es就包含了前三部分。 另外，现在的数据体系中，不会是单独一个组件而存在，而是多个组件或者说上述所有组件的共同合作结果。 比如一个响应用户请求的系统： 需要一个高速缓存来快速响应某些通用请求 需要一个数据库来存储所有的信息 需要一个全文索引来方便查找 需要一个消息队列来处理异步任务 三个系统设计关键问题 可靠性 提供客户需要的功能 容忍客户错误或者不正确的操作 足够强的性能 足够强的安全性 可扩展性 可维护性 可靠性首先需要注意的是，可靠性并不意味着我们需要对所有可能发生的故障或者意外事件都要进行处理。追求无穷的可靠性，意味着无穷的成本。 因此，可靠性或者说容错是有针对性的，或者说有范围的。 MTTF：平均无故障事件 错误类型： 硬件错误：一般而言可以通过硬件冗余进行处理 软件错误：相对难有快速解决方案，只能通过经验或者监控来缓解 人为失误：比如配置错误 精心设计API 沙盒或者dry run 充分测试 亡羊补牢，这需要快速回滚等支持 监控 可扩展性首先的问题是如何描述性能，一般而言关心吞吐量(throughput)，也就是从server角度来看，单位时间内能够处理请求的数目。吞吐量和latency是相关的，throughput = 1 / latency。 另外一个角度是从客户角度来看，也就是响应时间（response time），从客户发送请求，到返回结果的间隔。 这些描述，一般而言可以从统计学的角度来看，也就是平均数，中位数， 95%（比95%的请求都要高），99%甚至99.99%。这些统计信息往往和服务质量目标（Service Level Objective）或者服务质量协议(Service Level Agreements)绑定在一起。 其次，对于扩展，可以从两个方面看： 保持资源不变，增加负载会如何 保持性能不变，增加多少资源才能满足增加负载的需求 应付扩展 垂直扩容：升级机器性能 水平扩容：增加更加多的机器（可以利用廉价机器） 有状态服务一般会优先考虑垂直扩容，直到实在无法满足需求才考虑水平扩容；而分布式或者无服务的服务，水平扩容十分合适。但实际中，还是service speicified。 例如，即使两个系统的数据吞吐量折算下来是一样的，但是为每秒处理1000,000次请求(每个大小为KB)而设计的系统，与每分钟3个请求（每个大小2GB ）设计的系统会大不相同。 而且系统需求本身也是难以在一开始就被定义好的，整个service生命周期可能会发生变动或者其他情况。因此，快速迭代是一种增加扩展型的办法。 可维护性维护他人留下的系统往往是令人不快的。换个角度，在设计之时就可以特别关注设计的三个原则： 可运维性：方便运营团队来保持系统稳定 监控 自动化 排除单点热点 良好的文档和易于理解的操作模式 良好的默认设置 尝试自我修复 log，方便回顾 简单性：简化系统设计，方便工程师理解系统 使用通用”语言”，比如SQL，而不是新发明 定义好好的抽象，通用语言其实也是一种抽象 可演化性：后续工程师能轻松进行改进来满足需求变更，或者说能够快速演化，这需要好的抽象等等","categories":[],"tags":[{"name":"Storage","slug":"Storage","permalink":"http://yoursite.com/tags/Storage/"},{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"系统设计","slug":"系统设计","permalink":"http://yoursite.com/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"}]}]}